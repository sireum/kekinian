// #Sireum
/*
 Copyright (c) 2017-2025, Robby, Kansas State University
 All rights reserved.

 Redistribution and use in source and binary forms, with or without
 modification, are permitted provided that the following conditions are met:

 1. Redistributions of source code must retain the above copyright notice, this
    list of conditions and the following disclaimer.
 2. Redistributions in binary form must reproduce the above copyright notice,
    this list of conditions and the following disclaimer in the documentation
    and/or other materials provided with the distribution.

 THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
 ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
 WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
 DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
 ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
 (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
 LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND
 ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
 SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 */
package org.sireum.cli

import org.sireum._
import org.sireum.message.Reporter
import org.sireum.presentasi.Presentation

object Presentasi {

  @datatype trait Media {
    def filename: String
    def duration: Z
    def timeline: Z
  }

  @datatype class Image(val filename: String, val timeline: Z) extends Media {
    @strictpure override def duration: Z = 0
  }

  @datatype class Sound(val filepath: Os.Path, val text: String, val duration: Z, val timeline: Z) extends Media {
    override def filename: String = {
      return filepath.name
    }
  }

  @datatype class Video(val filepath: Os.Path, val duration: Z, val timeline: Z, val start: F64, val end: F64,
                        val muted: B, val volume: F64, val rate: F64) extends Media {
    override def filename: String = {
      return filepath.name
    }
  }

  val INVALID_ARGS: Z = -2
  val INVALID_PATH: Z = -3
  val INVALID_SPEC: Z = -4
  val INVALID_RESOURCE: Z = -4
  val NO_FFMPEG: Z = -5
  val kind: String = "Presentasi"

  def printHelp(help: String): Z = {
    println(help)
    println()
    println(
      st"""Available MaryTTS voices are: cmu-bdl-hsmm, cmu-rms-hsmm, cmu-slt-hsmm, dfki-obadiah-hsmm, dfki-prudence-hsmm, dfki-spike-hsmm
          |
          |For AWS, please refer to https://docs.aws.amazon.com/polly/latest/dg/voicelist.html
          |
          |For Azure, please refer to https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-text-to-speech""".render)
    return 0
  }

  def gen(o: Cli.SireumPresentasiGenOption, reporter: Reporter): Z = {

    @pure def formatTime(millis: Z): String = {
      def format(n: Z, digits: Z): String = {
        var r: String = s"$n"
        for (_ <- 0 until (digits - r.size)) {
          r = s"0$r"
        }
        return r
      }
      val ms = millis % 1000
      val s = millis / 1000
      val m = s / 60
      val h = m / 60
      return s"${format(h, 2)}:${format(m % 60, 2)}:${format(s % 60, 2)}:${format(ms, 3)}"
    }

    @pure def localTemplate(timeline: Z, i: Z, prevTimelineOpt: Option[Z]): ST = {
      prevTimelineOpt match {
        case Some(prevTimeline) =>
          if (prevTimeline == timeline) {
            return st"""final long t_$i = t_${i - 1};"""
          } else {
            return st"""final long t_$i = t_${i - 1} + ${timeline - prevTimelineOpt.get}L; // $timeline (${formatTime(timeline)})"""
          }
        case _ =>
          return st"""final long t_$i = ${timeline}L; // $timeline (${formatTime(timeline)})"""
      }
    }

    @strictpure def soundTemplate(filepath:String, timeline: Z, i: Z, prevTimelineOpt: Option[Z], text: String): ST =
      st"""${localTemplate(timeline, i, prevTimelineOpt)}
          |medias.add(new Sound("/audio/$filepath", t_$i, "${ops.StringOps(text).escapeST}"));"""

    @strictpure def imageTemplate(filename: String, timeline: Z, i: Z, prevTimelineOpt: Option[Z], n: Z): ST =
      st"""${localTemplate(timeline, i, prevTimelineOpt)}
          |medias.add(new Image("/image/$filename", t_$i)); // #$n"""

    @strictpure def videoTemplate(filename: String, timeline: Z, muted: B, rate:F64, start: F64, end: F64, i: Z,
                                  prevTimelineOpt: Option[Z], n: Z): ST =
      st"""${localTemplate(timeline, i, prevTimelineOpt)}
          |medias.add(new Video("/video/$filename", t_$i, $muted, $rate, $start, $end));  // #$n"""

    @strictpure def presentasiTemplate(name: String, granularity: Z, vseekDelay: Z, textVolume: F64, end: Z, medias: ISZ[ST]): ST =
      st"""// Auto-generated by Sireum Presentasi
          |import javafx.application.Application;
          |import javafx.application.Platform;
          |import javafx.geometry.Rectangle2D;
          |import javafx.scene.Scene;
          |import javafx.scene.image.ImageView;
          |import javafx.scene.layout.StackPane;
          |import javafx.scene.media.MediaPlayer;
          |import javafx.scene.media.MediaView;
          |import javafx.stage.Screen;
          |import javafx.stage.Stage;
          |import javafx.util.Duration;
          |
          |import java.awt.GraphicsConfiguration;
          |import java.awt.GraphicsEnvironment;
          |import java.io.File;
          |import java.io.FileWriter;
          |import java.net.URL;
          |import java.util.ArrayList;
          |import java.util.HashMap;
          |import java.util.LinkedList;
          |import java.util.List;
          |import java.util.concurrent.TimeUnit;
          |import java.util.concurrent.Executors;
          |import java.util.concurrent.ScheduledExecutorService;
          |import java.util.stream.Collectors;
          |
          |import org.monte.media.av.Format;
          |import org.monte.media.av.codec.video.VideoFormatKeys;
          |import org.monte.media.math.Rational;
          |import org.monte.media.screenrecorder.ScreenRecorder;
          |import org.monte.media.screenrecorder.MouseConfigs;
          |
          |public class $name extends Application {
          |
          |    public final static long TIMELINE_GRANULARITY = $granularity;
          |    public final static long VSEEK_DELAY = $vseekDelay;
          |    public final static double TEXT_VOLUME = $textVolume;
          |
          |    public final static HashMap<String, javafx.scene.media.Media> mediaMap = new HashMap<String, javafx.scene.media.Media>();
          |
          |    public static javafx.scene.media.Media getJfxMedia(String uri) {
          |        javafx.scene.media.Media r = mediaMap.get(uri);
          |        if (r == null) {
          |           r = new javafx.scene.media.Media(uri);
          |           mediaMap.put(uri, r);
          |        }
          |        return r;
          |    }
          |
          |    public interface Media {
          |        String getUri();
          |        boolean isReady();
          |        boolean hasError();
          |        long getDurationMillis();
          |        long getTimeline();
          |    }
          |
          |    public final static class Image implements Media {
          |        public final String uri;
          |        public final ImageView imageView;
          |        private final long timeline;
          |
          |        public Image(final String path, final long timeline) {
          |            this.uri = getResourceUri(path);
          |            this.timeline = timeline;
          |            this.imageView = new ImageView(new javafx.scene.image.Image(uri));
          |        }
          |
          |        public String getUri() { return this.uri; }
          |
          |        public boolean isReady() {
          |            return true;
          |        }
          |
          |        public boolean hasError() {
          |            return false;
          |        }
          |
          |        public long getDurationMillis() {
          |            return 0L;
          |        }
          |
          |        public long getTimeline() {
          |            return this.timeline;
          |        }
          |    }
          |
          |    public final static class Sound implements Media {
          |        public final String uri;
          |        private final long timeline;
          |        private final String text;
          |        public MediaPlayer mediaPlayer;
          |        private boolean ready = false;
          |        private boolean error = false;
          |        private long duration = 0L;
          |
          |        public Sound(final String path, final long timeline, final String text) {
          |            this.uri = getResourceUri(path);
          |            this.timeline = timeline;
          |            this.text = text;
          |            try {
          |              this.mediaPlayer = new MediaPlayer(getJfxMedia(this.uri));
          |              this.mediaPlayer.setOnReady(() -> {
          |                  this.ready = true;
          |                  this.duration = (long) Math.ceil(mediaPlayer.getTotalDuration().toMillis());
          |              });
          |              this.mediaPlayer.setOnError(() -> this.error = true);
          |            } catch (Throwable e) {
          |              e.printStackTrace();
          |              System.err.println("Could not load: " + path);
          |              System.err.flush();
          |              System.exit(-1);
          |            }
          |        }
          |
          |        public String getUri() { return this.uri; }
          |
          |        public boolean isReady() {
          |            return this.ready;
          |        }
          |
          |        public boolean hasError() {
          |            return this.error;
          |        }
          |
          |        public long getDurationMillis() {
          |            return this.duration;
          |        }
          |
          |        public long getTimeline() {
          |            return this.timeline;
          |        }
          |
          |        public String getText() {
          |            return this.text;
          |        }
          |    }
          |
          |    public final static class Video implements Media {
          |        public final String uri;
          |        private final long timeline;
          |        public MediaView mediaView;
          |        public final boolean muted;
          |        public final double rate;
          |        public final double startMillis;
          |        public final double endMillis;
          |        private boolean ready;
          |        private boolean error;
          |        private long duration;
          |
          |        public Video(final String path, final long timeline, final boolean muted, final double rate, final double startMs, final double endMs) {
          |            this.uri = getResourceUri(path);
          |            this.timeline = timeline;
          |            this.rate = rate;
          |            this.startMillis = startMs;
          |            this.endMillis = endMs;
          |            this.muted = muted;
          |            try {
          |              final MediaPlayer mediaPlayer = new MediaPlayer(getJfxMedia(this.uri));
          |              mediaPlayer.setOnReady(() -> {
          |                  this.ready = true;
          |                  this.duration = (long) Math.ceil(mediaPlayer.getTotalDuration().toMillis());
          |              });
          |              mediaPlayer.setOnError(() -> this.error = true);
          |              this.mediaView = new MediaView(mediaPlayer);
          |            } catch (Throwable e) {
          |              e.printStackTrace();
          |              System.err.println("Could not load: " + path);
          |              System.err.flush();
          |              System.exit(-1);
          |            }
          |        }
          |
          |        public String getUri() { return this.uri; }
          |
          |        public boolean isReady() {
          |            return this.ready;
          |        }
          |
          |        public boolean hasError() { return this.error; }
          |
          |        public long getDurationMillis() {
          |            return this.duration;
          |        }
          |
          |        public long getTimeline() {
          |            return this.timeline;
          |        }
          |    }
          |
          |    private final LinkedList<Media> medias = new LinkedList<>();
          |    private Stage stage = null;
          |    private long startTime = 0;
          |    private int slideNo = 0;
          |    private boolean fullScreen = true;
          |    private double width = -1;
          |    private double height = -1;
          |    private boolean record = false;
          | 
          |    public static String getResourceUri(final String path) {
          |        try {
          |            final URL url = Presentasi.class.getResource(path);
          |            if (url != null) {
          |                return url.toURI().toASCIIString();
          |            }
          |            throw new RuntimeException("Could not load " + path);
          |        } catch (final Throwable t){
          |            t.printStackTrace();
          |        }
          |        Platform.exit();
          |        return null;
          |    }
          |
          |    @Override
          |    public void init() {
          |        final List<String> args = getParameters().getRaw();
          |        if (args.size() > 0) {
          |            for (String arg : getParameters().getRaw()) {
          |                try {
          |                    int i = arg.indexOf('x');
          |                    if ("-r".equals(arg)) {
          |                       record = true;
          |                    } else if (i >= 0) {
          |                        width = Integer.parseInt(arg.substring(0, i));
          |                        height = Integer.parseInt(arg.substring(i + 1));
          |                        fullScreen = false;
          |                    } else if (arg.charAt(0) == '#') {
          |                        slideNo = Integer.parseInt(arg.substring(1));
          |                        startTime = 0;
          |                    } else {
          |                        startTime = Long.parseLong(arg);
          |                        slideNo = 0;
          |                    }
          |                } catch (Throwable t) {
          |                    System.err.println("Invalid argument " + arg);
          |                    System.err.flush();
          |                    Platform.exit();
          |                }
          |            }
          |        }
          |
          |        ${(medias, "\n")}
          |
          |        final long end = ${end}L; // ${formatTime(end)}
          |
          |        if (width == -1 || height == -1) {
          |            final Rectangle2D rect = Screen.getPrimary().getBounds();
          |            width = rect.getWidth();
          |            height = rect.getHeight();
          |        }
          |
          |        for (final Media media : medias) {
          |            final String uri = media.getUri();
          |            System.out.print("Loading " + uri + " ... ");
          |            System.out.flush();
          |            while (!media.isReady()) {
          |                if (media.hasError()) {
          |                    System.err.println("failed");
          |                    System.err.flush();
          |                    Platform.exit();
          |                }
          |                sleep(100);
          |            }
          |            System.out.println("done");
          |            System.out.flush();
          |        }
          |        
          |        final GraphicsConfiguration gc = GraphicsEnvironment.getLocalGraphicsEnvironment().getDefaultScreenDevice().getDefaultConfiguration();
          |
          |        final File dir = new File(new File(new File("out"), "presentasi"), this.getClass().getSimpleName());
          |        if (record) dir.mkdirs();
          |
          |        final Thread thread = new Thread(() -> {
          |            while (Presentasi.this.stage == null) Presentasi.sleep(100);
          |            final int size = medias.size();
          |            long start = System.currentTimeMillis();
          |            int i = 0;
          |            if (slideNo > 0) {
          |                int j = 0;
          |                while (i < size && j < slideNo) {
          |                    if (!(medias.get(i) instanceof Sound)) {
          |                        j = j + 1;
          |                    }
          |                    i++;
          |                }
          |                while (i < size && medias.get(i) instanceof Sound) i++;
          |                if (i < size) start = start - medias.get(i).getTimeline();
          |            } else if (startTime > 0) {
          |                while (i < size && medias.get(i).getTimeline() < startTime) {
          |                    i++;
          |                }
          |                while (i < size && medias.get(i) instanceof Sound) i++;
          |                if (i < size) start = start - medias.get(i).getTimeline();
          |            }
          |            final ArrayList<String> vtt = new ArrayList<>();
          |            final ArrayList<String> sounds = new ArrayList<>();
          |            vtt.add("WEBVTT");
          |            final int[] vttIndex = new int[] { 1 };
          |            final long[] soundBeginTime = new long[] { 0 };
          |            ScreenRecorder recorderTemp = null;
          |
          |            try {
          |                final int fps = 30;
          |                final int bitDepth = 24;
          |                final Format fileFormat = new Format(VideoFormatKeys.MediaTypeKey, VideoFormatKeys.MediaType.FILE,
          |                        VideoFormatKeys.MimeTypeKey, VideoFormatKeys.MIME_AVI);
          |                final Format screenFormat = new Format(VideoFormatKeys.MediaTypeKey, VideoFormatKeys.MediaType.VIDEO,
          |                        VideoFormatKeys.EncodingKey, VideoFormatKeys.ENCODING_AVI_TECHSMITH_SCREEN_CAPTURE,
          |                        VideoFormatKeys.CompressorNameKey, VideoFormatKeys.COMPRESSOR_NAME_AVI_TECHSMITH_SCREEN_CAPTURE,
          |                        VideoFormatKeys.DepthKey, bitDepth,
          |                        VideoFormatKeys.FrameRateKey, Rational.valueOf(fps),
          |                        VideoFormatKeys.QualityKey, 1.0f,
          |                        VideoFormatKeys.KeyFrameIntervalKey, fps / 2);
          |                final Format mouseFormat = new Format(VideoFormatKeys.MediaTypeKey, VideoFormatKeys.MediaType.VIDEO,
          |                        VideoFormatKeys.EncodingKey, MouseConfigs.ENCODING_BLACK_CURSOR,
          |                        VideoFormatKeys.FrameRateKey, Rational.valueOf(fps));
          |    
          |                recorderTemp = new ScreenRecorder(gc, null,
          |                        fileFormat, screenFormat, mouseFormat,
          |                        null, dir);
          |            } catch (final Throwable t) {
          |                t.printStackTrace();
          |                System.exit(1);
          |            }
          |
          |            final ScreenRecorder recorder = recorderTemp;
          |            final ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor();
          |            stage.setOnShown(event -> scheduler.schedule(() -> {
          |                if (record) {
          |                    try {
          |                        recorder.start();
          |                    } catch (final Throwable t) {
          |                        t.printStackTrace();
          |                        System.exit(1);
          |                    }
          |                }
          |                soundBeginTime[0] = System.currentTimeMillis();
          |            }, 1, TimeUnit.SECONDS));
          |            while (i < size) {
          |                final Media media = medias.get(i);
          |                while (System.currentTimeMillis() - start <= media.getTimeline()) Presentasi.sleep(TIMELINE_GRANULARITY);
          |                if (media instanceof Sound) {
          |                    final Sound sound = ((Sound) media);
          |                    final MediaPlayer player = sound.mediaPlayer;
          |                    player.setVolume(TEXT_VOLUME);
          |                    player.setOnPlaying(() -> {
          |                        final long soundBegin = System.currentTimeMillis() - soundBeginTime[0];
          |                        final long soundEnd = soundBegin + sound.duration;
          |                        sounds.add(soundBegin + "," + soundEnd + "," + sound.uri + "," + 0 + "," + 0);
          |                        if (!sound.text.isEmpty()) {
          |                            vtt.add("");
          |                            vtt.add("" + vttIndex[0]++);
          |                            vtt.add(formatCcTime(soundBegin) + " --> " + formatCcTime(soundEnd));
          |                            vtt.add(sound.text);
          |                        }
          |                    });
          |                    player.setOnEndOfMedia(() -> player.dispose());
          |                    player.play();
          |                } else if (media instanceof Image) {
          |                    final Image graphic = (Image) media;
          |                    final StackPane root = new StackPane();
          |                    final ImageView imageView = graphic.imageView;
          |                    root.getChildren().add(imageView);
          |                    imageView.setPreserveRatio(true);
          |                    imageView.setSmooth(true);
          |                    imageView.setFitWidth(width);
          |                    imageView.setFitHeight(height);
          |                    stage.getScene().setRoot(root);
          |                    Platform.runLater(() -> stage.show());
          |                } else if (media instanceof Video) {
          |                    final Video video = (Video) media;
          |                    final StackPane root = new StackPane();
          |                    final MediaView mediaView = video.mediaView;
          |                    root.getChildren().add(mediaView);
          |                    mediaView.setPreserveRatio(true);
          |                    mediaView.setSmooth(true);
          |                    mediaView.setFitWidth(width);
          |                    mediaView.setFitHeight(height);
          |                    final MediaPlayer player = mediaView.getMediaPlayer();
          |                    player.setStartTime(Duration.millis(video.startMillis));
          |                    player.setRate(video.rate);
          |                    player.setOnEndOfMedia(() -> player.dispose());
          |                    if (video.endMillis > 0.0) player.setStopTime(Duration.millis(video.endMillis));
          |                    player.setVolume(1.0);
          |                    player.setMute(video.muted);
          |                    player.setOnPlaying(() -> {
          |                        if (!video.muted) {
          |                            final long soundBegin = System.currentTimeMillis() - soundBeginTime[0];
          |                            final long soundEnd = soundBegin + video.duration;
          |                            sounds.add(soundBegin + "," + soundEnd + "," + video.uri + "," + video.startMillis + "," + video.endMillis);
          |                        }
          |                    });
          |                    player.setOnEndOfMedia(() -> player.dispose());
          |                    Platform.runLater(() -> {
          |                        player.play();
          |                        if (video.startMillis > 0) {
          |                            Presentasi.sleep(VSEEK_DELAY);
          |                        }
          |                        stage.getScene().setRoot(root);
          |                        stage.show();
          |                    });
          |                }
          |                i++;
          |            }
          |            while (System.currentTimeMillis() - start <= end) Presentasi.sleep(TIMELINE_GRANULARITY);
          |            if (record) {
          |                try {
          |                    recorder.stop();
          |                    File vttFile = new File(dir, this.getClass().getSimpleName() + ".vtt");
          |                    if (vttFile.exists()) vttFile.delete();
          |                    FileWriter fw = new FileWriter(vttFile);
          |                    fw.write(vtt.stream().collect(Collectors.joining(System.lineSeparator())));
          |                    fw.flush();
          |                    fw.close();
          |                    File csvFile = new File(dir, this.getClass().getSimpleName() + ".csv");
          |                    if (csvFile.exists()) csvFile.delete();
          |                    fw = new FileWriter(csvFile);
          |                    fw.write(sounds.stream().collect(Collectors.joining(System.lineSeparator())));
          |                    fw.flush();
          |                    fw.close();
          |                    System.out.println("Wrote " + recorder.getCreatedMovieFiles().getFirst().getCanonicalPath());
          |                    System.out.println("Wrote " + vttFile.getCanonicalPath());
          |                    System.out.println("Wrote " + csvFile.getCanonicalPath());
          |                    System.out.flush();
          |                } catch (final Throwable t) {
          |                    t.printStackTrace();
          |                    System.exit(1);
          |                }
          |            }
          |            scheduler.shutdown();
          |            Platform.exit();
          |        });
          |        thread.setDaemon(true);
          |        thread.start();
          |    }
          |
          |    public static void sleep(final long millis) {
          |        try {
          |            Thread.sleep(millis);
          |        } catch (final Throwable t) {
          |            // skip
          |        }
          |    }
          |
          |    public static String formatCcTime(final Long millis) {
          |        return String.format("%02d:%02d:%02d.%03d", TimeUnit.MILLISECONDS.toHours(millis),
          |                TimeUnit.MILLISECONDS.toMinutes(millis) % TimeUnit.HOURS.toMinutes(1),
          |                TimeUnit.MILLISECONDS.toSeconds(millis) % TimeUnit.MINUTES.toSeconds(1), millis % 1000);
          |    }
          |
          |    @Override
          |    public void start(final Stage primaryStage) {
          |        primaryStage.setFullScreenExitHint("");
          |        primaryStage.setFullScreen(fullScreen);
          |        primaryStage.setResizable(!fullScreen);
          |        final Scene scene = new Scene(new StackPane(), width, height);
          |        primaryStage.setScene(scene);
          |        this.stage = primaryStage;
          |    }
          |
          |}"""

    val path: Os.Path = o.args match {
      case ISZ() => return printHelp(o.help)
      case ISZ(p, _*) => Os.path(p).canon
    }

    val hasFFmpeg = proc"ffmpeg -h".run().ok
    if (o.slides && !hasFFmpeg) {
      reporter.error(None(), kind, "FFmpeg is required when using --slides")
    }
//    if (o.record && !hasFFmpeg) {
//      reporter.error(None(), kind, "FFmpeg is required when using --record")
//    }
    if (reporter.hasError) {
      reporter.printMessages()
      return NO_FFMPEG
    }

    val presentasi = path / "bin" / "presentasi.cmd"
    val voiceArg: String = o.voice match {
      case Some(v) => v
      case _ => o.service match {
        case Cli.SireumPresentasiGenService.Mary => "dfki-spike-hsmm"
        case Cli.SireumPresentasiGenService.Aws => "Amy"
        case Cli.SireumPresentasiGenService.Azure => "en-GB-RyanNeural"
      }
    }
    val args = ISZ(presentasi.string, o.service.string, voiceArg) ++ ops.ISZOps(o.args).drop(1)
    val specs: ISZ[Presentation] = if (presentasi.exists) {
      val outTemp = Os.temp()
      val r = SlangRunner.run(Cli.SireumSlangRunOption("", args, F, None(), Some(outTemp.string), F, F))
      if (r != 0) {
        eprintln(outTemp.read)
        return INVALID_SPEC
      }

      org.sireum.presentasi.JSON.toPresentation(outTemp.read) match {
        case Either.Left(obj) => ISZ(obj)
        case _ =>
          eprintln(s"Failed to process $path")
          return INVALID_SPEC
      }
    } else {
      Presentasi.Ext.parseMarkdowns(ops.ISZOps(args).drop(1), path, reporter)
    }
    if (reporter.hasIssue) {
      reporter.printMessages()
      return INVALID_SPEC
    }

    val resources = path / "jvm" / "src" / "main" / "resources"
    val source = path / "jvm" / "src" / "main" / "java"
    val image = resources / "image"
    val video = resources / "video"
    image.mkdirAll()
    video.mkdirAll()

    val audioDir = (resources / "audio").canon
    var audio = audioDir
    val service: Cli.SireumPresentasiText2speechService.Type = o.service match {
      case Cli.SireumPresentasiGenService.Azure =>
        audio = audio / "azure"
        Cli.SireumPresentasiText2speechService.Azure
      case Cli.SireumPresentasiGenService.Aws =>
        audio = audio / "aws"
        Cli.SireumPresentasiText2speechService.Aws
      case Cli.SireumPresentasiGenService.Mary =>
        audio = audio / "marytts"
        Cli.SireumPresentasiText2speechService.Mary
    }
    o.voice match {
      case Some(voice) => audio = audio / voice
      case _ =>
    }
    audio.mkdirAll()

    @pure def isGeneratedAudio(p: Os.Path): B = {
      if (p.ext == "wav" || p.ext == "mp3") {
        val cis = conversions.String.toCis(p.name)
        if (cis.size > 7 && cis(6) == '-' && ops.ISZOps(ops.ISZOps(cis).take(6)).
          forall((c: C) => 'A' <= c && c <= 'Z' || '0' <= c && c <= '9') ||
          cis.size > 11 && cis(cis.size - 11) == '-' && ops.ISZOps(ops.ISZOps(ops.ISZOps(cis).drop(cis.size - 10)).dropRight(4)).
            forall((c: C) => 'A' <= c && c <= 'Z' || '0' <= c && c <= '9')) {
          return T
        }
      }
      return F
    }

    var generatedAudioFiles = HashSSet.empty[Os.Path]
    for (p <- audio.list if isGeneratedAudio(p)) {
      generatedAudioFiles = generatedAudioFiles + p
      if (o.force) {
        p.removeAll()
      }
    }

    val (format, ext): (Cli.SireumPresentasiText2speechOutputFormat.Type, String) = o.outputFormat match {
      case Cli.SireumPresentasiGenOutputFormat.Mp3 if o.service != Cli.SireumPresentasiGenService.Mary =>
        (Cli.SireumPresentasiText2speechOutputFormat.Mp3, "mp3")
      case _ => (Cli.SireumPresentasiText2speechOutputFormat.Wav, "wav")
    }

    for (spc <- specs) {
      var spec = spc
      if (o.slice.nonEmpty) {
        var entries = ISZ[org.sireum.presentasi.Presentation.Entry]()
        var indices = HashSet.empty[Z]
        for (i <- o.slice) {
          Z(ops.StringOps(i).trim) match {
            case Some(n) => indices = indices + n
            case _ =>
              reporter.error(None(), kind, s"Invalid slice argument: $i")
              reporter.printMessages()
              return INVALID_ARGS
          }
        }
        for (i <- spec.entries.indices if indices.contains(i)) {
          entries = entries :+ spec.entries(i)
        }
        spec = spec(entries = entries)
      }

      def processText(text: String, start: Z): (ISZ[Media], Z) = {
        def fingerprint(t: String): String = {
          val c = crypto.SHA3.init256
          c.update(conversions.String.toU8is(t))
          return st"${(ops.ISZOps(c.finalise()).take(3), "")}".render
        }

        def process(sound: Sound): Sound = {
          var sub = conversions.String.fromCis(
            for (c <- conversions.String.toCis(
              if (sound.text.size > 15) ops.StringOps(sound.text).substring(0, 15) else sound.text)) yield
              if (('a' <= c && c <= 'z') || ('A' <= c && c <= 'Z') || ('0' <= c && c <= '9')) c else '_')
          var filename = s"${fingerprint(sound.text)}-$sub.$ext"
          var p = audio / filename
          if (!p.exists) {
            sub = conversions.String.fromCis(
              for (c <- conversions.String.toCis(
                if (sound.text.size > 32) ops.StringOps(sound.text).substring(0, 32) else sound.text)) yield
                if (('a' <= c && c <= 'z') || ('A' <= c && c <= 'Z') || ('0' <= c && c <= '9')) c else '_')
            filename = s"$sub-${fingerprint(sound.text)}.$ext"
            p = audio / filename
          }
          val temp = Os.tempFix("", ".txt")
          temp.writeOver(sound.text)
          val engine: Cli.SireumPresentasiText2speechEngine.Type = o.engine match {
            case Cli.SireumPresentasiGenEngine.Neural => Cli.SireumPresentasiText2speechEngine.Neural
            case Cli.SireumPresentasiGenEngine.Standard => Cli.SireumPresentasiText2speechEngine.Standard
          }
          val code = text2speech(Cli.SireumPresentasiText2speechOption(
            help = "",
            args = ISZ(temp.string),
            force = F,
            output = Some(p.string),
            service = service,
            voice = o.voice,
            awsPath = o.awsPath,
            gender = o.gender,
            key = o.key,
            lang = o.lang,
            outputFormat = format,
            region = o.region,
            voiceLang = o.voiceLang,
            engine = engine
          ))
          temp.removeAll()
          println(s"Loading $p ...")
          val durOpt = Ext.getSoundDuration(p.toUri)
          println()
          generatedAudioFiles = generatedAudioFiles - p
          durOpt match {
            case Some(dur) if code == 0 => return sound(filepath = p, duration = dur)
            case _ =>
              reporter.error(None(), kind, s"""Failed to load: "${sound.text}"""")
              return sound
          }
        }

        var sounds = ISZ[Media]()

        def newSound(curr: Z): Sound = {
          return Sound(Os.path(""), "", 0, curr)
        }

        def parseVolume(vol: String, vpath: String): F64 = {
          F64(vol) match {
            case Some(v) if 0.0 <= v && v <= 1.0 =>
              return v
            case _ =>
              reporter.error(None(), kind, s"Invalid volume for $vpath [0.0 .. 1.0]: $vol")
              return 1.0
          }
        }

        var currSound = newSound(start)

        def storeSound(): Unit = {
          if (currSound.text != "") {
            val sound = process(currSound)
            sounds = sounds :+ sound
            currSound = newSound(sound.timeline + sound.duration)
          } else {
            currSound = newSound(currSound.timeline)
          }
        }

        for (l <- ops.StringOps(text).split((c: C) => c == '\n')) {
          ops.StringOps(l).trim match {
            case string"" =>
              storeSound()
              currSound = currSound(timeline = currSound.timeline + spec.textDelay)
            case line =>
              val lineOps = ops.StringOps(line)
              if (lineOps.startsWith("[") && lineOps.endsWith("]")) {
                val dir = ops.StringOps(lineOps.substring(1, line.size - 1)).trim
                Z(dir) match {
                  case Some(n) =>
                    storeSound()
                    currSound = currSound(timeline = currSound.timeline + n)
                  case _ =>
                    var volume: F64 = 0.0
                    val apath: Os.Path = if (ops.StringOps(dir).indexOf(';') >= 0) {
                      ops.StringOps(dir).split((c: C) => c == ';') match {
                        case ISZ(vol, p) =>
                          volume = parseVolume(ops.StringOps(vol).trim, p)
                          Os.path(ops.StringOps(p).trim)
                        case _ =>
                          reporter.error(None(), kind, s"Could not parse: $line (expecting [ <volume> ; ] <audio-path> )")
                          Os.path("")
                      }
                    } else {
                      Os.path(dir)
                    }
                    if (apath.string == "") {
                      // skip
                    } else if (apath.exists) {
                      val target = audio / apath.name
                      if (target.string != apath.string) {
                        apath.copyOverTo(target)
                        println(s"Wrote $target")
                        println()
                      }
                      Ext.getSoundDuration(apath.toUri) match {
                        case Some(dur) =>
                          if (currSound.text != "") {
                            storeSound()
                            currSound = currSound(timeline = currSound.timeline + spec.textDelay)
                          }
                          currSound = currSound(filepath = target, duration = dur)
                          sounds = sounds :+ currSound
                          currSound = newSound(currSound.timeline + dur)
                        case _ => reporter.error(None(), kind, s"Failed to load: $apath")
                      }
                    } else {
                      reporter.error(None(), kind, s"$apath does not exist")
                    }
                }
              } else {
                currSound = currSound(text = if (currSound.text == "") line else s"${currSound.text} $line")
              }
          }
        }

        storeSound()

        if (sounds.isEmpty) {
          return (sounds, start)
        } else {
          val last = sounds(sounds.size - 1)
          return (sounds, last.timeline + last.duration)
        }
      }

      val outDir = path / "out" / "presentasi" / spec.name
      val slides = outDir / "Slides"
      outDir.mkdirAll()
      for (f <- outDir.list if !ops.StringOps(f.name).startsWith("ScreenRecording")) {
        f.removeAll()
      }
      slides.mkdirAll()
      var medias = ISZ[Media]()
      var curr: Z = 0
      var first = T
      var transcript = ISZ[ST]()
      val hasCWebP = proc"cwebp -h".run().ok

      for (entry <- spec.entries) {
        def processTarget(d: Os.Path, e: Presentation.Entry): (String, Os.Path) = {
          val p = Os.path(e.path)
          val target = d / p.name
          if (target.canon.string != p.canon.string) {
            p.copyOverTo(target)
            println(s"Wrote $target")
            println()
          }
          println(s"Loading $p ...")
          return (p.toUri, target)
        }
        def addTranscriptEntry(p: Os.Path, sounds: ISZ[Media]): Unit = {
          var transcriptItems = ISZ[ST]()
          for (sound <- sounds) {
            val text = sound.asInstanceOf[Sound].text
            if (text.size > 0) {
              transcriptItems = transcriptItems :+ st"* ${spec.cc.get(text).getOrElse(text)}"
            }
          }
          transcript = transcript :+
            st"""![${p.name}](${slides.relativize(p)})
                |
                |${(transcriptItems, "\n\n")}"""
        }
        entry match {
          case entry: Presentation.Slide =>
            val (uri, target) = processTarget(image, entry)
            val ok = Ext.checkImage(uri)
            println()
            if (ok) {
              val gap: Z = if (entry.delay == 0) if (first) 0 else spec.delay else entry.delay
              medias = medias :+ Image(target.name, curr + gap)
              val (sounds, last) = processText(entry.text, curr)
              var p = Os.path(entry.path)
              if (hasCWebP && o.slides && p.ext == "png") {
                val webp = slides / s"${ops.StringOps(p.name).substring(0, p.name.size - p.ext.size - 1)}.webp"
                if (!webp.exists || webp.lastModified < p.lastModified) {
                  Os.proc(ISZ("cwebp", "-lossless", p.string, "-o", webp.string)).runCheck()
                }
                p = webp
              }
              addTranscriptEntry(p, sounds)
              medias = medias ++ sounds
              curr = last
            } else {
              reporter.error(None(), kind, s"Could not load image ${entry.path}")
            }
          case entry: Presentation.Video =>
            val (uri, target) = processTarget(video, entry)
            val durOpt = Ext.getVideoDuration(uri)
            println()
            durOpt match {
              case Some(dur) =>
                val durR = conversions.Z.toR(dur)
                val start: F64 = if (entry.start < 0.0) {
                  0.0
                } else if (conversions.F64.toR(entry.start) > durR) {
                  reporter.error(None(), kind, s"Invalid start for video ${entry.path}: ${entry.start}")
                  0.0
                } else {
                  entry.start
                }
                val end: F64 = if (entry.end == 0.0 || conversions.F64.toR(entry.end) > durR) {
                  0.0
                } else if (entry.end < start) {
                  reporter.error(None(), kind, s"Invalid end for video ${entry.path}: ${entry.end}")
                  0.0
                } else {
                  entry.end
                }
                val volume: F64 = if (0.0 <= entry.volume && entry.volume <= 1.0) {
                  entry.volume
                } else {
                  reporter.error(None(), kind, s"Invalid volume for video ${entry.path} [0.0 .. 1.0]: ${entry.volume}")
                  1.0
                }
                val gap: Z = if (entry.delay == 0) if (first) 0 else spec.delay else entry.delay
                val rate: F64 = if (0.0 < entry.rate && entry.rate <= 8.0) {
                  entry.rate
                } else {
                  reporter.error(None(), kind, s"Invalid rate for video ${entry.path} (0.0 .. 8.0]: ${entry.volume}")
                  1.0
                }
                medias = medias :+ Video(target, dur, curr + gap, start, end, entry.textOpt.nonEmpty, volume, rate)
                val newCurr = curr + gap + (
                  if (end == 0.0) conversions.R.toZ(durR / conversions.F64.toR(rate)) + 1
                  else conversions.R.toZ(conversions.F64.toR(end - start) / conversions.F64.toR(rate)) + 1)
                var p = Os.path(entry.path)
                if (o.slides) {
                  val ss = entry.start / 1000d
                  val t: ISZ[String] =
                    if (entry.end > 0d) ISZ[String]("-t", ((entry.end - entry.start) / 1000d).string)
                    else ISZ[String]()
                  val gif = slides / s"${ops.StringOps(p.name).substring(0, p.name.size - p.ext.size - 1)}.${o.videoHeight}.$ss${if (t.isEmpty) "" else s"-${t(1)}"}.gif"
                  if (!gif.exists || gif.lastModified < p.lastModified) {
                    println(s"Generating $gif ...")
                    Os.proc(ISZ[String]("ffmpeg", "-y", "-i", p.value, "-ss", ss.string) ++ t ++ ISZ[String]("-loop", "0", "-filter_complex",
                      s"fps=${o.videoFps}, scale=-1:${o.videoHeight}[s]; [s]split[a][b]; [a]palettegen[palette]; [b][palette]paletteuse",
                      gif.string
                    )).runCheck()
                    println()
                  }
                  p = gif
                }
                entry.textOpt match {
                  case Some(text) =>
                    val (sounds, last) = processText(text, curr)
                    addTranscriptEntry(p, sounds)
                    medias = medias ++ sounds
                    curr = if (entry.useVideoDuration) newCurr else last
                  case _ =>
                    addTranscriptEntry(p, ISZ())
                    curr = newCurr
                }
              case _ =>
                reporter.error(None(), kind, s"Could not load video ${entry.path}")
            }
        }
        first = F
      }

      reporter.printMessages()
      if (reporter.hasIssue) {
        return INVALID_RESOURCE
      }

      var mediaSTs = ISZ[ST]()
      var previousTimelineOpt: Option[Z] = None()
      val audioDirUriSize = audioDir.toUri.size
      var n = 0
      var cc = ISZ[ST]()

      for (i <- medias.indices) {
        medias(i) match {
          case media: Image =>
            mediaSTs = mediaSTs :+ imageTemplate(media.filename, media.timeline, i, previousTimelineOpt, n)
            n = n + 1
          case media: Video =>
            mediaSTs = mediaSTs :+ videoTemplate(media.filename, media.timeline, media.muted,
              media.rate, media.start, media.end, i, previousTimelineOpt, n)
            n = n + 1
          case media: Sound =>
            val mediaUri = media.filepath.toUri
            val ccText = spec.cc.get(media.text).getOrElse(media.text)
            mediaSTs = mediaSTs :+ soundTemplate(ops.StringOps(mediaUri).substring(audioDirUriSize, mediaUri.size),
              media.timeline, i, previousTimelineOpt, ccText)
            val t = media.timeline + spec.vseekDelay
            if (ccText.size > 0) {
              val startTime = Ext.formatCcTime(o.srt, t + o.cc)
              val endTime = Ext.formatCcTime(o.srt, t + o.cc + media.duration)
              cc = cc :+
                st"""${cc.size + 1}
                    |$startTime --> $endTime
                    |$ccText"""
            }
        }
        previousTimelineOpt = Some(medias(i).timeline)
      }

      val f = source / s"${spec.name}.java"
      val transcriptFile = slides / s"readme.md"
      val ccFile = outDir / s"${spec.name}.${if (o.srt) "srt" else "vtt"}"
      val end: Z = if (medias.size > 0) {
        val last = medias(medias.size - 1)
        last.timeline + last.duration + spec.trailing
      } else {
        0
      }

      f.writeOver(presentasiTemplate(spec.name, spec.granularity, spec.vseekDelay, spec.textVolume, end, mediaSTs).render)
      println(s"Wrote $f")
      if (o.record) {
        if (o.srt) {
          ccFile.writeOver(st"${(cc, "\n\n")}".render)
        } else {
          ccFile.writeOver(
            st"""WEBVTT
                |
                |${(cc, "\n\n")}""".render
          )
        }
        println(s"Wrote $ccFile")
      }
      if (o.slides) {
        transcriptFile.writeOver(st"${(transcript, "\n\n----\n\n")}".render)
        println(s"Wrote $transcriptFile")
      }
      if (o.clean) {
        for (f <- generatedAudioFiles.elements) {
          f.removeAll()
          println(s"Removed $f")
        }
      }
    }
    return 0
  }

  def text2speech(o: Cli.SireumPresentasiText2speechOption): Z = {

    def maryTTS(javaHome: Os.Path, maryTtsJar: Os.Path, voice: String, input: Os.Path, output: Os.Path): OsProto.Proc.Result = {
      val javaExe: Os.Path = if (Os.isWin) javaHome / "bin" / "java.exe" else javaHome / "bin" / "java"
      return proc"$javaExe -jar $maryTtsJar -o $output -v $voice -i $input".env(ISZ("JAVA_HOME" ~> javaHome.string)).console.runCheck()
    }

    @pure def isSoundFile(path: Os.Path): B = {
      return path.ext == "mp3" || path.ext == "wav" || path.ext == "webm" || path.ext == "ogg"
    }

    @pure def outputFile(output: Os.Path, inputFilename: String, i: Z, line: String, ext: String): Os.Path = {
      var num: String = s"$i-"
      while (num.size < 3) {
        num = s"0$num"
      }
      if (output == Os.cwd) {
        var cis = ISZ[C]()
        for (c <- conversions.String.toCStream(line).take(16)) {
          cis = cis :+ (if ('A' <= c && c <= 'Z' || '0' <= c && c <= '9') c else '_')
        }
        return output.canon / s"$num${conversions.String.fromCis(cis)}.$ext"
      } else if (isSoundFile(output)) {
        return output
      } else {
        return output.up.canon / s"$num$inputFilename.$ext"
      }
    }

    val inputFile: Os.Path = o.args match {
      case ISZ() =>
        return printHelp(o.help)
      case ISZ(p) =>
        val f = Os.path(p)
        if (!f.isFile) {
          eprintln(s"$p is not a file")
          Os.exit(-1)
          halt("")
        }
        f
      case _ =>
        printHelp(o.help)
        return -1
    }
    val javaHome = SireumApi.javaHomeOpt.get
    val maryTtsJar: Os.Path = SireumApi.homeOpt.get / "lib" / "marytts_text2wav.jar"

    val output: Os.Path = o.output match {
      case Some(p) =>
        val f = Os.path(p)
        if (!isSoundFile(f)) {
          f.mkdirAll()
        }
        f
      case _ => Os.cwd
    }

    o.service match {
      case Cli.SireumPresentasiText2speechService.Azure =>
        val key: String = o.key match {
          case Some(k) => k
          case _ =>
            Os.env("AZURE_KEY") match {
              case Some(k) => k
              case _ =>
                eprintln("Please supply your Azure subscription key via CLi option --key or via the AZURE_KEY env var")
                Os.exit(-1)
                halt("")
            }
        }
        var i = 1
        val tmp = Os.tempFix("", if (Os.isWin) ".bat" else "")
        val echoOffOpt: Option[String] = if (Os.isWin) Some("@echo off") else None()
        tmp.removeOnExit()
        val voice = o.voice.getOrElseEager("en-GB-RyanNeural")
        val (format, ext): (String, String) = o.outputFormat match {
          case Cli.SireumPresentasiText2speechOutputFormat.Mp3 => ("audio-48khz-192kbitrate-mono-mp3", "mp3")
          case Cli.SireumPresentasiText2speechOutputFormat.Wav => ("raw-48khz-16bit-mono-pcm", "wav")
          case Cli.SireumPresentasiText2speechOutputFormat.Webm => ("webm-24khz-16bit-mono-opus", "webm")
          case Cli.SireumPresentasiText2speechOutputFormat.Ogg => ("ogg-48khz-16bit-mono-opus", "ogg")
        }
        for (line <- inputFile.readLineStream if ops.StringOps(line).trim.size > 0) {
          val out = outputFile(output, inputFile.name, i, line, ext)
          if (!out.exists || o.force || out.size == 0) {
            println(s"Synthesizing: $line")
            tmp.writeOver(
              st"""$echoOffOpt
                  |curl --location --request POST 'https://${o.region.get}.tts.speech.microsoft.com/cognitiveservices/v1' --header 'Ocp-Apim-Subscription-Key: $key' --header 'Content-Type: application/ssml+xml' --header 'X-Microsoft-OutputFormat: $format' --header 'User-Agent: curl' --data-raw '<speak version="1.0" xml:lang="${o.lang.get}"><voice xml:lang="${o.voiceLang.get}" xml:gender="${o.gender.get}" name="$voice">${ops.StringOps(line).replaceAllLiterally("'", "'\\''")}</voice></speak>' -o $out""".render)
            tmp.chmod("+x")
            proc"$tmp".console.runCheck()
            if (ext == "wav") {
              Ext.pcm2wav(out, 48000)
            }
            println()
          } else {
            println(s"Skipping already generated: $line")
            println()
          }
          i = i + 1
        }
      case Cli.SireumPresentasiText2speechService.Aws =>
        val aws = Os.path(o.awsPath.get)
        val tmp = Os.tempFix("", if (Os.isWin) ".bat" else "")
        val echoOffOpt: Option[String] = if (Os.isWin) Some("@echo off") else None()
        tmp.removeOnExit()
        var i = 1
        val voice = o.voice.getOrElseEager("Amy")
        val engine: String = o.engine match {
          case Cli.SireumPresentasiText2speechEngine.Neural => "neural"
          case Cli.SireumPresentasiText2speechEngine.Standard => "standard"
        }
        val (outputFormat, ext, rate): (String, String, Z) = o.outputFormat match {
          case Cli.SireumPresentasiText2speechOutputFormat.Mp3 => ("mp3", "mp3", 24000)
          case Cli.SireumPresentasiText2speechOutputFormat.Ogg => ("ogg_vorbis", "ogg", 24000)
          case Cli.SireumPresentasiText2speechOutputFormat.Wav => ("pcm", "wav", 16000)
          case Cli.SireumPresentasiText2speechOutputFormat.Webm =>
            eprintln("AWS does not support webm output format")
            return -1
        }
        for (line <- inputFile.readLineStream if ops.StringOps(line).trim.size > 0) {
          val out = outputFile(output, inputFile.name, i, line, ext)
          if (!out.exists || o.force) {
            println(s"Synthesizing: $line")
            tmp.writeOver(
              st"""$echoOffOpt
                  |$aws polly synthesize-speech --engine $engine --language-code ${o.lang} --output-format $outputFormat --sample-rate $rate --text "<speak>$line</speak>" --text-type "ssml" --voice-id "$voice" $out""".render)
            tmp.chmod("+x")
            proc"$tmp".console.runCheck()
            if (ext == "wav") {
              Ext.pcm2wav(out, 16000)
            }
            println()
          } else {
            println(s"Skipping already generated: $line")
            println()
          }
          i = i + 1
        }
      case Cli.SireumPresentasiText2speechService.Mary =>
        var i = 1
        val tmp = Os.temp()
        tmp.removeOnExit()
        val voice = o.voice.getOrElseEager("dfki-spike-hsmm")
        for (line <- inputFile.readLineStream if ops.StringOps(line).trim.size > 0) {
          val out = outputFile(output, inputFile.name, i, line, "wav")
          if (!out.exists || o.force) {
            println(s"Synthesizing: $line")
            tmp.writeOver(line)
            maryTTS(javaHome, maryTtsJar, voice, tmp, out)
            println()
          } else {
            println(s"Skipping already generated: $line")
            println()
          }
          i = i + 1
        }
    }
    return 0
  }

  @ext("Presentasi_Ext") object Ext {

    def checkImage(uri: String): B = $

    def getSoundDuration(uri: String): Option[Z] = $

    def getVideoDuration(uri: String): Option[Z] = $

    def pcm2wav(path: Os.Path, srate: Z): Unit = $

    def shutdown(): Unit = $

    def parseMarkdowns(args: ISZ[String], path: Os.Path, reporter: message.Reporter): ISZ[presentasi.Presentation] = $

    def formatCcTime(isSrt: B, ms: Z): String = $
  }
}
